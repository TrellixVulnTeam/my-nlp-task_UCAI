{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MRPC...\n",
      "\tCompleted!\n"
     ]
    }
   ],
   "source": [
    "''' Script for downloading all GLUE data.\n",
    "\n",
    "Note: for legal reasons, we are unable to host MRPC.\n",
    "You can either use the version hosted by the SentEval team, which is already tokenized, \n",
    "or you can download the original data from (https://download.microsoft.com/download/D/4/6/D46FF87A-F6B9-4252-AA8B-3604ED519838/MSRParaphraseCorpus.msi) and extract the data from it manually.\n",
    "For Windows users, you can run the .msi file. For Mac and Linux users, consider an external library such as 'cabextract' (see below for an example).\n",
    "You should then rename and place specific files in a folder (see below for an example).\n",
    "\n",
    "mkdir MRPC\n",
    "cabextract MSRParaphraseCorpus.msi -d MRPC\n",
    "cat MRPC/_2DEC3DBE877E4DB192D17C0256E90F1D | tr -d $'\\r' > MRPC/msr_paraphrase_train.txt\n",
    "cat MRPC/_D7B391F9EAFF4B1B8BCE8F21B20B1B61 | tr -d $'\\r' > MRPC/msr_paraphrase_test.txt\n",
    "rm MRPC/_*\n",
    "rm MSRParaphraseCorpus.msi\n",
    "'''\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import argparse\n",
    "import tempfile\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "TASKS = [\"CoLA\", \"SST\", \"MRPC\", \"QQP\", \"STS\", \"MNLI\", \"SNLI\", \"QNLI\", \"RTE\", \"WNLI\", \"diagnostic\"]\n",
    "TASK2PATH = {\"CoLA\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FCoLA.zip?alt=media&token=46d5e637-3411-4188-bc44-5809b5bfb5f4',\n",
    "             \"SST\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8',\n",
    "             \"MRPC\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc',\n",
    "             \"QQP\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQQP.zip?alt=media&token=700c6acf-160d-4d89-81d1-de4191d02cb5',\n",
    "             \"STS\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSTS-B.zip?alt=media&token=bddb94a7-8706-4e0d-a694-1109e12273b5',\n",
    "             \"MNLI\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FMNLI.zip?alt=media&token=50329ea1-e339-40e2-809c-10c40afff3ce',\n",
    "             \"SNLI\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSNLI.zip?alt=media&token=4afcfbb2-ff0c-4b2d-a09a-dbf07926f4df',\n",
    "             \"QNLI\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQNLI.zip?alt=media&token=c24cad61-f2df-4f04-9ab6-aa576fa829d0',\n",
    "             \"RTE\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FRTE.zip?alt=media&token=5efa7e85-a0bb-4f19-8ea2-9e1840f077fb',\n",
    "             \"WNLI\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FWNLI.zip?alt=media&token=068ad0a0-ded7-4bd7-99a5-5e00222e0faf',\n",
    "             \"diagnostic\":'https://storage.googleapis.com/mtl-sentence-representations.appspot.com/tsvsWithoutLabels%2FAX.tsv?GoogleAccessId=firebase-adminsdk-0khhl@mtl-sentence-representations.iam.gserviceaccount.com&Expires=2498860800&Signature=DuQ2CSPt2Yfre0C%2BiISrVYrIFaZH1Lc7hBVZDD4ZyR7fZYOMNOUGpi8QxBmTNOrNPjR3z1cggo7WXFfrgECP6FBJSsURv8Ybrue8Ypt%2FTPxbuJ0Xc2FhDi%2BarnecCBFO77RSbfuz%2Bs95hRrYhTnByqu3U%2FYZPaj3tZt5QdfpH2IUROY8LiBXoXS46LE%2FgOQc%2FKN%2BA9SoscRDYsnxHfG0IjXGwHN%2Bf88q6hOmAxeNPx6moDulUF6XMUAaXCSFU%2BnRO2RDL9CapWxj%2BDl7syNyHhB7987hZ80B%2FwFkQ3MEs8auvt5XW1%2Bd4aCU7ytgM69r8JDCwibfhZxpaa4gd50QXQ%3D%3D'}\n",
    "\n",
    "MRPC_TRAIN = 'https://s3.amazonaws.com/senteval/senteval_data/msr_paraphrase_train.txt'\n",
    "MRPC_TEST = 'https://s3.amazonaws.com/senteval/senteval_data/msr_paraphrase_test.txt'\n",
    "\n",
    "def download_and_extract(task, data_dir):\n",
    "    print(\"Downloading and extracting %s...\" % task)\n",
    "    data_file = \"%s.zip\" % task\n",
    "    urllib.request.urlretrieve(TASK2PATH[task], data_file)\n",
    "    with zipfile.ZipFile(data_file) as zip_ref:\n",
    "        zip_ref.extractall(data_dir)\n",
    "    os.remove(data_file)\n",
    "    print(\"\\tCompleted!\")\n",
    "\n",
    "def format_mrpc(data_dir, path_to_data):\n",
    "    print(\"Processing MRPC...\")\n",
    "    mrpc_dir = os.path.join(data_dir, \"MRPC\")\n",
    "    if not os.path.isdir(mrpc_dir):\n",
    "        os.mkdir(mrpc_dir)\n",
    "    if path_to_data:\n",
    "        mrpc_train_file = os.path.join(path_to_data, \"msr_paraphrase_train.txt\")\n",
    "        mrpc_test_file = os.path.join(path_to_data, \"msr_paraphrase_test.txt\")\n",
    "    else:\n",
    "        mrpc_train_file = os.path.join(mrpc_dir, \"msr_paraphrase_train.txt\")\n",
    "        mrpc_test_file = os.path.join(mrpc_dir, \"msr_paraphrase_test.txt\")\n",
    "        urllib.request.urlretrieve(MRPC_TRAIN, mrpc_train_file)\n",
    "        urllib.request.urlretrieve(MRPC_TEST, mrpc_test_file)\n",
    "    assert os.path.isfile(mrpc_train_file), \"Train data not found at %s\" % mrpc_train_file\n",
    "    assert os.path.isfile(mrpc_test_file), \"Test data not found at %s\" % mrpc_test_file\n",
    "#     urllib.request.urlretrieve(TASK2PATH[\"MRPC\"], os.path.join(mrpc_dir, \"dev_ids.tsv\"))\n",
    "\n",
    "    dev_ids = []\n",
    "    with open(os.path.join(mrpc_dir, \"dev_ids.tsv\")) as ids_fh:\n",
    "        for row in ids_fh:\n",
    "            dev_ids.append(row.strip().split('\\t'))\n",
    "\n",
    "    with open(mrpc_train_file) as data_fh, \\\n",
    "         open(os.path.join(mrpc_dir, \"train.tsv\"), 'w') as train_fh, \\\n",
    "         open(os.path.join(mrpc_dir, \"dev.tsv\"), 'w') as dev_fh:\n",
    "        header = data_fh.readline()\n",
    "        train_fh.write(header)\n",
    "        dev_fh.write(header)\n",
    "        for row in data_fh:\n",
    "            label, id1, id2, s1, s2 = row.strip().split('\\t')\n",
    "            if [id1, id2] in dev_ids:\n",
    "                dev_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n",
    "            else:\n",
    "                train_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n",
    "\n",
    "    with open(mrpc_test_file) as data_fh, \\\n",
    "            open(os.path.join(mrpc_dir, \"test.tsv\"), 'w') as test_fh:\n",
    "        header = data_fh.readline()\n",
    "        test_fh.write(\"index\\t#1 ID\\t#2 ID\\t#1 String\\t#2 String\\n\")\n",
    "        for idx, row in enumerate(data_fh):\n",
    "            label, id1, id2, s1, s2 = row.strip().split('\\t')\n",
    "            test_fh.write(\"%d\\t%s\\t%s\\t%s\\t%s\\n\" % (idx, id1, id2, s1, s2))\n",
    "    print(\"\\tCompleted!\")\n",
    "\n",
    "def download_diagnostic(data_dir):\n",
    "    print(\"Downloading and extracting diagnostic...\")\n",
    "    if not os.path.isdir(os.path.join(data_dir, \"diagnostic\")):\n",
    "        os.mkdir(os.path.join(data_dir, \"diagnostic\"))\n",
    "    data_file = os.path.join(data_dir, \"diagnostic\", \"diagnostic.tsv\")\n",
    "    urllib.request.urlretrieve(TASK2PATH[\"diagnostic\"], data_file)\n",
    "    print(\"\\tCompleted!\")\n",
    "    return\n",
    "\n",
    "def get_tasks(task_names):\n",
    "    task_names = task_names.split(',')\n",
    "    if \"all\" in task_names:\n",
    "        tasks = TASKS\n",
    "    else:\n",
    "        tasks = []\n",
    "        for task_name in task_names:\n",
    "            assert task_name in TASKS, \"Task %s not found!\" % task_name\n",
    "            tasks.append(task_name)\n",
    "    return tasks\n",
    "\n",
    "def main():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--data_dir', help='directory to save data to', type=str, default='glue_data')\n",
    "#     parser.add_argument('--tasks', help='tasks to download data for as a comma separated string',\n",
    "#                         type=str, default='all')\n",
    "#     parser.add_argument('--path_to_mrpc', help='path to directory containing extracted MRPC data, msr_paraphrase_train.txt and msr_paraphrase_text.txt',\n",
    "#                         type=str, default='')\n",
    "#     args = parser.parse_args(arguments)\n",
    "    data_dir = \"./glue_data/\"\n",
    "    tasks = ['MRPC']\n",
    "    if not os.path.isdir(data_dir):\n",
    "        os.mkdir(args.data_dir)\n",
    "#     tasks = get_tasks(tasks)\n",
    "    path_to_mrpc = '/home1/shenxing/GLUE/MSRP'\n",
    "    for task in tasks:\n",
    "        if task == 'MRPC':\n",
    "            format_mrpc(data_dir, path_to_mrpc)\n",
    "        elif task == 'diagnostic':\n",
    "            download_diagnostic(args.data_dir)\n",
    "        else:\n",
    "            download_and_extract(task, args.data_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/shenxing/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_checkpoint='/home1/shenxing/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "/home1/shenxing/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
    "init_vars = tf.train.list_variables(init_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bert/embeddings/LayerNorm/beta', [768]),\n",
       " ('bert/embeddings/LayerNorm/gamma', [768]),\n",
       " ('bert/embeddings/position_embeddings', [512, 768]),\n",
       " ('bert/embeddings/token_type_embeddings', [2, 768]),\n",
       " ('bert/embeddings/word_embeddings', [30522, 768]),\n",
       " ('bert/encoder/layer_0/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_0/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_0/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_0/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_0/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_0/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_0/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_0/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_0/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_0/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_0/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_0/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_0/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_0/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_0/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_0/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_1/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_1/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_1/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_1/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_1/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_1/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_1/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_1/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_1/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_1/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_1/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_1/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_1/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_1/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_1/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_1/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_10/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_10/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_10/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_10/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_10/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_10/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_10/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_10/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_10/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_10/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_10/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_10/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_10/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_10/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_10/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_10/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_11/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_11/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_11/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_11/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_11/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_11/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_11/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_11/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_11/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_11/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_11/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_11/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_11/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_11/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_11/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_11/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_2/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_2/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_2/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_2/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_2/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_2/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_2/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_2/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_2/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_2/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_2/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_2/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_2/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_2/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_2/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_2/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_3/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_3/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_3/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_3/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_3/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_3/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_3/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_3/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_3/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_3/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_3/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_3/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_3/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_3/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_3/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_3/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_4/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_4/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_4/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_4/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_4/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_4/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_4/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_4/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_4/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_4/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_4/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_4/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_4/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_4/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_4/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_4/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_5/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_5/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_5/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_5/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_5/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_5/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_5/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_5/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_5/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_5/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_5/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_5/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_5/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_5/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_5/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_5/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_6/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_6/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_6/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_6/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_6/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_6/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_6/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_6/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_6/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_6/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_6/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_6/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_6/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_6/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_6/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_6/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_7/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_7/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_7/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_7/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_7/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_7/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_7/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_7/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_7/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_7/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_7/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_7/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_7/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_7/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_7/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_7/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_8/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_8/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_8/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_8/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_8/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_8/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_8/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_8/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_8/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_8/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_8/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_8/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_8/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_8/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_8/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_8/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_9/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_9/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_9/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_9/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_9/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_9/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_9/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_9/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_9/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_9/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_9/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_9/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_9/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_9/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_9/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_9/output/dense/kernel', [3072, 768]),\n",
       " ('bert/pooler/dense/bias', [768]),\n",
       " ('bert/pooler/dense/kernel', [768, 768]),\n",
       " ('cls/predictions/output_bias', [30522]),\n",
       " ('cls/predictions/transform/LayerNorm/beta', [768]),\n",
       " ('cls/predictions/transform/LayerNorm/gamma', [768]),\n",
       " ('cls/predictions/transform/dense/bias', [768]),\n",
       " ('cls/predictions/transform/dense/kernel', [768, 768]),\n",
       " ('cls/seq_relationship/output_bias', [2]),\n",
       " ('cls/seq_relationship/output_weights', [2, 768])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
