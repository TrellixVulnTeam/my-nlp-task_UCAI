{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-52cb30e33c0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import bert.modeling as modeling\n",
    "import collections\n",
    "import csv\n",
    "import os\n",
    "import bert.modeling as modeling\n",
    "import bert.optimization as optimization\n",
    "import bert.tokenization as tokenization \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "tf_config = tf.ConfigProto(allow_soft_placement = True,log_device_placement=True)\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "\n",
    "\n",
    "#路径设置\n",
    "# BERT_BASE_DIR='/home1/shenxing/uncased_L-12_H-768_A-12/'\n",
    "BERT_BASE_DIR='/home1/shenxing/chinese_L-12_H-768_A-12/'\n",
    "GLUE_DIR='/home1/shenxing//bert/glue_data/'\n",
    "vocab_file=os.path.join(BERT_BASE_DIR,\"vocab.txt\")\n",
    "bert_config_file = os.path.join(BERT_BASE_DIR,\"bert_config.json\")\n",
    "init_checkpoint = os.path.join(BERT_BASE_DIR,\"bert_model.ckpt\")\n",
    "max_seq_length=128 \n",
    "train_batch_size=32 \n",
    "learning_rate=2e-5 \n",
    "num_train_epochs=3.0 \n",
    "output_dir=\"~/bert_test_model\"\n",
    "use_one_hot_embeddings = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test sample \n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "is_training = False\n",
    "input_ids = tf.constant([[31, 51, 99], [15, 5, 0]])\n",
    "input_mask = tf.constant([[1, 1, 1], [1, 1, 0]])\n",
    "token_type_ids = tf.constant([[0, 0, 1], [0, 2, 0]])\n",
    "segment_ids = tf.constant([[0, 0, 0], [1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session(config = tf_config)\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "is_training = False\n",
    "input_ids = tf.placeholder(shape=[None,3],dtype=tf.int32)\n",
    "# input_ids = tf.constant([[31, 51, 99], [15, 5, 0]])\n",
    "input_mask = tf.placeholder(shape=[None,3],dtype=tf.int32)\n",
    "# input_mask = tf.constant([[1, 1, 1], [1, 1, 0]])\n",
    "token_type_ids = tf.placeholder(shape=[None,3],dtype=tf.int32)\n",
    "\n",
    "segment_ids = tf.placeholder(shape=[None,3],dtype=tf.int32)\n",
    "# token_type_ids = tf.constant([[0, 0, 1], [0, 2, 0]])\n",
    "# segment_ids = tf.constant([[0, 0, 0], [1, 1, 1]])\n",
    "\n",
    "\n",
    "model = modeling.BertModel(\n",
    "      config=bert_config,\n",
    "      is_training=is_training,\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      token_type_ids=segment_ids,\n",
    "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,init_checkpoint)\n",
    "sequence_output = model.get_sequence_output()\n",
    "\n",
    "# (assignment_map, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../rasa_nlu/bert_source_code/')\n",
    "import modeling\n",
    "import optimization\n",
    "import tokenization \n",
    "# from run_pretraining import get_masked_lm_output\n",
    "# from create_pretraining_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_pretraining_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.flags\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string(\"input_file\", None,\n",
    "                    \"Input raw text file (or comma-separated list of files).\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output_file\", None,\n",
    "    \"Output TF example file (or comma-separated list of files).\")\n",
    "\n",
    "flags.DEFINE_string(\"vocab_file\", None,\n",
    "                    \"The vocabulary file that the BERT model was trained on.\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"do_lower_case\", True,\n",
    "    \"Whether to lower case the input text. Should be True for uncased \"\n",
    "    \"models and False for cased models.\")\n",
    "\n",
    "flags.DEFINE_integer(\"max_seq_length\", 128, \"Maximum sequence length.\")\n",
    "\n",
    "flags.DEFINE_integer(\"max_predictions_per_seq\", 20,\n",
    "                     \"Maximum number of masked LM predictions per sequence.\")\n",
    "\n",
    "flags.DEFINE_integer(\"random_seed\", 12345, \"Random seed for data generation.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"dupe_factor\", 10,\n",
    "    \"Number of times to duplicate the input data (with different masks).\")\n",
    "\n",
    "flags.DEFINE_float(\"masked_lm_prob\", 0.15, \"Masked LM probability.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"short_seq_prob\", 0.1,\n",
    "    \"Probability of creating sequences which are shorter than the \"\n",
    "    \"maximum length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_lower_case = True\n",
    "max_seq_length = 128\n",
    "max_predictions_per_seq = 20\n",
    "masked_lm_prob = 0.15\n",
    "short_seq_prob = 0.1\n",
    "dupe_factor = 10\n",
    "input_file = '/home1/shenxing/rasa_bert_nlu/data/bert_data/test.txt'\n",
    "vocab_file = '/home1/shenxing/rasa_bert_nlu/bert_pretrain_model/chinese_L-12_H-768_A-12/vocab.txt'\n",
    "output_file = '/home1/shenxing/rasa_bert_nlu/data/bert_data/test_output.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Writing to output files ***\n",
      "INFO:tensorflow:  /home1/shenxing/rasa_bert_nlu/data/bert_data/test_output.txt\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 好 哇 , 今 天 过 得 怎 么 样 [SEP] 你 ##聶 [MASK] , [MASK] 天 过 [MASK] 怎 么 样 你 是 谁 [MASK] 你 从 哪 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 1962 1505 117 791 1921 6814 2533 2582 720 3416 102 872 18536 103 117 103 1921 6814 103 2582 720 3416 872 3221 6443 103 872 794 1525 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 14 15 17 20 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 1962 1505 791 2533 8024 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 是 谁 ， 你 从 哪 里 来 [SEP] 你 好 哇 [MASK] 今 [MASK] 过 得 怎 么 样 你 是 谁 ， 你 从 哪 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 3221 6443 8024 872 794 1525 7027 3341 102 872 1962 1505 103 791 103 6814 2533 2582 720 3416 872 3221 6443 8024 872 794 1525 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 13 14 16 23 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 1505 117 1921 3221 8024 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 好 ##鯽 , 今 天 过 得 怎 么 样 [SEP] 你 [MASK] 谁 [MASK] 你 从 哪 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 1962 20868 117 791 1921 6814 2533 2582 720 3416 102 872 103 6443 103 872 794 1525 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 3 14 16 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 1505 3221 8024 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 是 [MASK] ， 你 从 哪 [MASK] 来 [SEP] 你 好 哇 , 今 天 过 得 怎 么 样 你 是 [MASK] ， 你 从 哪 里 [MASK] [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 3221 103 8024 872 794 1525 103 3341 102 872 1962 1505 117 791 1921 6814 2533 2582 720 3416 872 3221 103 8024 872 794 1525 7027 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 3 8 24 26 30 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 6443 7027 6443 872 3341 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 好 哇 , [MASK] 天 过 得 怎 [MASK] 样 [SEP] 你 好 哇 , 今 天 过 得 怎 么 [MASK] 你 是 谁 ， 你 从 [MASK] 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 1962 1505 117 103 1921 6814 2533 2582 103 3416 102 872 1962 1505 117 791 1921 6814 2533 2582 720 103 872 3221 6443 8024 872 794 103 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 5 10 22 23 30 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 791 720 720 3416 1525 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 好 哇 , 今 天 [MASK] 得 怎 么 [MASK] [SEP] 你 是 谁 ， [MASK] 从 哪 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 1962 1505 117 791 1921 103 2533 2582 720 103 102 872 3221 6443 8024 103 794 1525 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 7 11 17 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:masked_lm_ids: 6814 3416 872 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 是 [MASK] ， [MASK] 从 哪 里 来 [SEP] 你 好 [MASK] , 今 天 过 得 怎 [MASK] 样 你 是 谁 ， 你 ##field 哪 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 3221 103 8024 103 794 1525 7027 3341 102 872 1962 103 117 791 1921 6814 2533 2582 103 3416 872 3221 6443 8024 872 10901 1525 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 3 5 13 20 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 6443 872 1505 720 794 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 好 哇 , 今 天 过 得 [MASK] 么 样 [SEP] 你 是 谁 ， 你 从 哪 [MASK] [MASK] [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 1962 1505 117 791 1921 6814 2533 103 720 3416 102 872 3221 6443 8024 872 794 1525 103 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 9 20 21 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 2582 7027 3341 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 好 哇 , 今 天 [MASK] 得 怎 么 样 [SEP] [MASK] 是 谁 ， 你 从 圭 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 1962 1505 117 791 1921 103 2533 2582 720 3416 102 103 3221 6443 8024 872 794 1764 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 7 13 19 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 6814 872 1525 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 好 哇 , 今 天 过 得 怎 么 样 [SEP] 你 好 [MASK] ##諮 [MASK] 天 [MASK] 得 怎 [MASK] 样 你 是 谁 ， 你 从 哪 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 1962 1505 117 791 1921 6814 2533 2582 720 3416 102 872 1962 103 19381 103 1921 103 2533 2582 103 3416 872 3221 6443 8024 872 794 1525 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 15 16 17 19 22 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 1505 117 791 6814 720 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 好 哇 [MASK] 今 天 过 得 怎 么 样 [SEP] [MASK] 是 谁 ， [MASK] 从 哪 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 1962 1505 103 791 1921 6814 2533 2582 720 3416 102 103 3221 6443 8024 103 794 1525 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 4 13 17 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 117 872 872 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 好 哇 , [MASK] [MASK] 过 得 怎 么 [MASK] [SEP] 你 好 哇 , 今 天 过 得 怎 么 样 你 [MASK] 谁 ， 你 从 哪 里 [MASK] [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 1962 1505 117 103 103 6814 2533 2582 720 103 102 872 1962 1505 117 791 1921 6814 2533 2582 720 3416 872 103 6443 8024 872 794 1525 7027 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:masked_lm_positions: 5 6 11 25 32 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 791 1921 3416 3221 3341 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 是 谁 ， [MASK] 从 哪 里 ##唇 [SEP] 你 好 哇 , 今 天 [MASK] 得 怎 么 样 [MASK] 是 谁 ， 你 从 哪 里 [MASK] [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 3221 6443 8024 103 794 1525 7027 14592 102 872 1962 1505 117 791 1921 103 2533 2582 720 3416 103 3221 6443 8024 872 794 1525 7027 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 5 9 17 22 30 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 872 3341 6814 872 3341 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 好 哇 , 今 天 过 得 怎 么 [MASK] [SEP] think 好 哇 , 今 天 过 得 怎 ##軽 样 你 是 谁 ， 你 [MASK] [MASK] 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 1962 1505 117 791 1921 6814 2533 2582 720 103 102 12553 1962 1505 117 791 1921 6814 2533 2582 19788 3416 872 3221 6443 8024 872 103 103 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 11 13 22 29 30 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 3416 872 720 794 1525 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 是 ##咏 ， [MASK] 从 [MASK] 里 来 [SEP] 你 好 哇 , [MASK] 天 [MASK] 得 怎 么 样 你 是 谁 ， 你 从 哪 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 3221 14528 8024 103 794 103 7027 3341 102 872 1962 1505 117 103 1921 103 2533 2582 720 3416 872 3221 6443 8024 872 794 1525 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 3 5 7 15 17 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 6443 872 1525 791 6814 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 你 是 谁 ， 你 从 哪 里 [MASK] [SEP] [MASK] 是 谁 ， 你 从 哪 里 来 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 872 3221 6443 8024 872 794 1525 7027 103 102 103 3221 6443 8024 872 794 1525 7027 3341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 9 11 19 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 3341 872 3341 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:Wrote 16 total instances\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenization.FullTokenizer(\n",
    "  vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "input_files = []\n",
    "for input_pattern in input_file.split(\",\"):\n",
    "    input_files.extend(tf.gfile.Glob(input_pattern))\n",
    "\n",
    "rng = random.Random()\n",
    "instances = create_training_instances(\n",
    "  input_files, tokenizer, max_seq_length, dupe_factor,\n",
    "  short_seq_prob, masked_lm_prob, max_predictions_per_seq,\n",
    "  rng)\n",
    "\n",
    "output_files = output_file.split(\",\")\n",
    "tf.logging.info(\"*** Writing to output files ***\")\n",
    "for output_file in output_files:\n",
    "    tf.logging.info(\"  %s\", output_file)\n",
    "\n",
    "write_instance_to_example_files(instances, tokenizer, max_seq_length,\n",
    "                              max_predictions_per_seq, output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masked_lm_predictions(tokens, masked_lm_prob,\n",
    "                                 max_predictions_per_seq, vocab_words, rng):\n",
    "  \"\"\"Creates the predictions for the masked LM objective.\"\"\"\n",
    "\n",
    "  cand_indexes = []\n",
    "  for (i, token) in enumerate(tokens):\n",
    "    if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "      continue\n",
    "    cand_indexes.append(i)\n",
    "\n",
    "  rng.shuffle(cand_indexes)\n",
    "\n",
    "  output_tokens = list(tokens)\n",
    "\n",
    "  masked_lm = collections.namedtuple(\"masked_lm\", [\"index\", \"label\"])  # pylint: disable=invalid-name\n",
    "\n",
    "  num_to_predict = min(max_predictions_per_seq,\n",
    "                       max(1, int(round(len(tokens) * masked_lm_prob))))\n",
    "\n",
    "  masked_lms = []\n",
    "  covered_indexes = set()\n",
    "  for index in cand_indexes:\n",
    "    if len(masked_lms) >= num_to_predict:\n",
    "      break\n",
    "    if index in covered_indexes:\n",
    "      continue\n",
    "    covered_indexes.add(index)\n",
    "\n",
    "    masked_token = None\n",
    "    # 80% of the time, replace with [MASK]\n",
    "    if rng.random() < 0.8:\n",
    "      masked_token = \"[MASK]\"\n",
    "    else:\n",
    "      # 10% of the time, keep original\n",
    "      if rng.random() < 0.5:\n",
    "        masked_token = tokens[index]\n",
    "      # 10% of the time, replace with random word\n",
    "      else:\n",
    "        masked_token = vocab_words[rng.randint(0, len(vocab_words) - 1)]\n",
    "\n",
    "    output_tokens[index] = masked_token\n",
    "\n",
    "    masked_lms.append(masked_lm(index=index, label=tokens[index]))\n",
    "\n",
    "  masked_lms = sorted(masked_lms, key=lambda x: x.index)\n",
    "\n",
    "  masked_lm_positions = []\n",
    "  masked_lm_labels = []\n",
    "  for p in masked_lms:\n",
    "    masked_lm_positions.append(p.index)\n",
    "    masked_lm_labels.append(p.label)\n",
    "\n",
    "  return (output_tokens, masked_lm_positions, masked_lm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_token = \"[MASK]\"\n",
    "tokens = ['[CLS]', '你', '好', '哇', ',', '今', '天', '过', '得', '怎', '么', '样', '[SEP]']\n",
    "masked_lm_positions = [1]\n",
    "masked_lm_labels = []\n",
    "output_tokens = list(tokens)\n",
    "for position in masked_lm_positions:\n",
    "    masked_lm_labels.append(tokens[position])\n",
    "    output_tokens[position] = masked_token\n",
    "\n",
    "# masked_lm_weights = [1.0] * len(masked_lm_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '[MASK]', '好', '哇', ',', '今', '天', '过', '得', '怎', '么', '样', '[SEP]']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm_ids = tokenizer.convert_tokens_to_ids(masked_lm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[872]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm_weights = [1.0] * len(masked_lm_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm_weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
